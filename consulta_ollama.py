import os
from neo4j import GraphDatabase
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

# Carrega variÃ¡veis de ambiente do .env
load_dotenv()

# ConfiguraÃ§Ãµes do Neo4j via .env
NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USER")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")

driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

# ğŸŒ Contexto fixo sobre a Lei do Bem
contexto_base = """
A Lei do Bem (Lei nÂº 11.196/2005) oferece incentivos fiscais para empresas que realizam atividades de pesquisa e desenvolvimento (P&D) de inovaÃ§Ã£o tecnolÃ³gica no Brasil. Os principais objetivos sÃ£o:

- Estimular a inovaÃ§Ã£o tecnolÃ³gica nas empresas.
- Incentivar o investimento privado em P&D.
- Tornar o paÃ­s mais competitivo tecnologicamente.

Principais benefÃ­cios:

- DeduÃ§Ã£o de 20,4% a 34% do IRPJ e CSLL sobre gastos com P&D.
- ReduÃ§Ã£o de 50% do IPI na compra de mÃ¡quinas e equipamentos.
- DepreciaÃ§Ã£o e amortizaÃ§Ã£o acelerada de bens utilizados em P&D.
- IsenÃ§Ã£o de IR na remessa ao exterior para registro de patentes.

As empresas devem estar em lucro real e cumprir os critÃ©rios legais para obter os incentivos.
"""

# FunÃ§Ã£o para buscar contexto adicional no grafo
def buscar_contexto(termo):
    with driver.session() as session:
        query = """
        MATCH (b:Beneficio)
        WHERE toLower(b.descricao) CONTAINS toLower($termo)
        RETURN b.descricao AS beneficio
        LIMIT 5
        """
        resultados = session.run(query, termo=termo)
        contexto = [f"BenefÃ­cio identificado: {row['beneficio']}" for row in resultados]

        # Fallback: se nÃ£o encontrar, retorna 5 aleatÃ³rios
        if not contexto:
            query_fallback = """
            MATCH (b:Beneficio)
            RETURN b.descricao AS beneficio
            LIMIT 5
            """
            resultados = session.run(query_fallback)
            contexto = [f"BenefÃ­cio identificado: {row['beneficio']}" for row in resultados]

        return "\n".join(contexto)

# LLM local com Langchain + Ollama
llm = OllamaLLM(model="llama3")

# Template do prompt
prompt = PromptTemplate.from_template("""
VocÃª Ã© um especialista na Lei do Bem (Lei nÂº 11.196/2005). Responda com clareza e base legal Ã  pergunta abaixo, usando o contexto fornecido.

Contexto Fixo:
{contexto_base}

Contexto DinÃ¢mico do Grafo:
{contexto_grafo}

Pergunta:
{pergunta}

Resposta:
""")

# FunÃ§Ã£o principal
def responder(pergunta: str) -> str:
    contexto_grafo = buscar_contexto(pergunta)
    resposta = (prompt | llm).invoke({
        "contexto_base": contexto_base,
        "contexto_grafo": contexto_grafo,
        "pergunta": pergunta
    })
    return resposta

# ExecuÃ§Ã£o principal
if __name__ == "__main__":
    pergunta = input(">> ")
    resposta = responder(pergunta)
    print("\nResposta:\n", resposta)
